{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np , pandas as pd , copy\n",
    "from dimensions import dimensions\n",
    "from keys_list import keys_list\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_dict=np.load(\"../examples/googlenet.npy\", encoding='latin1').item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_copy=copy.deepcopy(pretrained_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame=pd.DataFrame(deep_copy)\n",
    "pd.set_option('precision', 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_frame['conv1_7x7_s2']['weights'].min())\n",
    "# print(data_frame['conv1_7x7_s2']['biases'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_list_biases=[]\n",
    "max_list_biases=[]\n",
    "\n",
    "min_list_weights=[]\n",
    "max_list_weights=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_frame.keys():\n",
    "    min_list_biases.append(data_frame[i]['biases'].min())\n",
    "    max_list_biases.append(data_frame[i]['biases'].max())\n",
    "    \n",
    "    min_list_weights.append(data_frame[i]['weights'].min())\n",
    "    max_list_weights.append(data_frame[i]['weights'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(min_list_biases)\n",
    "# print(max_list_biases)\n",
    "\n",
    "# print(min_list_weights)\n",
    "# print(max_list_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_biases  : -15.751750946044922 \n",
      "max_biases  :   8.003083229064941 \n",
      "min_weights :  -1.104335904121399 \n",
      "max_weights :   1.6037755012512207 \n",
      "len_weights :  2.70811128616333 \n",
      "len_biases :   23.754833221435547 \n"
     ]
    }
   ],
   "source": [
    "min_biases  = min(min_list_biases)\n",
    "max_biases  = max(max_list_biases)\n",
    "min_weights = min(min_list_weights)\n",
    "max_weights = max(max_list_weights)\n",
    "len_weights = max(max_list_weights) - min(min_list_weights)\n",
    "len_biases  = max(max_list_biases) - min(min_list_biases)\n",
    "print(\"min_biases  : {} \".format(min_biases))\n",
    "print(\"max_biases  :   {} \".format(max_biases))\n",
    "\n",
    "print(\"min_weights :  {} \".format(min_weights))\n",
    "print(\"max_weights :   {} \".format(max_weights))\n",
    "\n",
    "print(\"len_weights :  {} \".format(len_weights))\n",
    "print(\"len_biases :   {} \".format(len_biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(data_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data_frame[\"conv1_7x7_s2\"][\"weights\"].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data_frame[\"conv1_7x7_s2\"][\"biases\"].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=data_frame[\"conv1_7x7_s2\"][\"weights\"].flatten()\n",
    "biases=data_frame[\"conv1_7x7_s2\"][\"biases\"].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in keys_list:\n",
    "    if i == \"conv1_7x7_s2\":\n",
    "        continue\n",
    "    temp_weights=data_frame[i][\"weights\"].flatten() \n",
    "    weights=np.concatenate((weights,temp_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in keys_list:\n",
    "    if i == \"conv1_7x7_s2\":\n",
    "        continue\n",
    "    temp_biases=data_frame[i][\"biases\"].flatten() \n",
    "    biases=np.concatenate((biases,temp_biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6990272\n",
      "8280\n"
     ]
    }
   ],
   "source": [
    "print(len(weights))\n",
    "print(len(biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dimensions)\n",
    "sum_weights=0\n",
    "sum_biases=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dimensions:\n",
    "    partial_sum_weights=0\n",
    "    partial_sum_biases=0\n",
    "    if i == 'loss3_classifier':\n",
    "        partial_sum_weights=dimensions[i][0][0]*dimensions[i][0][1]\n",
    "    else:    \n",
    "        partial_sum_weights=dimensions[i][0][0]*dimensions[i][0][1]*dimensions[i][0][2]*dimensions[i][0][3]\n",
    "    \n",
    "    partial_sum_biases=dimensions[i][1]\n",
    "    sum_biases+=partial_sum_biases\n",
    "    sum_weights+=partial_sum_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sum_weights)\n",
    "# print(sum_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(min(biases))\n",
    "# print(max(biases))\n",
    "\n",
    "# print(min(weights))\n",
    "# print(max(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum=0\n",
    "# counter=0\n",
    "# for i in weights:\n",
    "#     i=abs(i)\n",
    "#     length=len(str(i))\n",
    "#     if length == 14:\n",
    "#         print (i,counter)\n",
    "#     counter+=1    \n",
    "#     if length > maximum :\n",
    "#         maximum = length\n",
    "# print(maximum)\n",
    "# print(max(len(str(weights))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6990272\n",
      "6697665\n",
      "0.9581408277102808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(weights))\n",
    "print(len(np.unique(weights)))\n",
    "print(len(np.unique(weights))/len(weights))\n",
    "# weights.shape\n",
    "weights_labels=np.zeros(shape=(len(weights),))\n",
    "weights_labels.shape\n",
    "radius=0.01\n",
    "steps = (max_weights - min_weights)/radius\n",
    "# print(steps)\n",
    "steps= int(steps)+1\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_in_list(list_input,item):\n",
    "    indices=[i for i,x in enumerate(list_input) if x==item] \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst): \n",
    "    return sum(lst) / len(lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzer(input_set,minimum,maximum,radius):\n",
    "    output_labels=np.zeros(shape=(len(input_set),))\n",
    "    output_centers = np.zeros(shape=(len(input_set),))\n",
    "    steps = (maximum - minimum)/radius\n",
    "    steps = int(steps)+1\n",
    "    center=minimum + radius\n",
    "    for i in range(steps):\n",
    "        lowerbound = center-radius #inclusive\n",
    "        upperbound = center+radius #non inclusive\n",
    "        index=0\n",
    "        for j in input_set :\n",
    "            if j >= lowerbound and j < upperbound :\n",
    "                output_labels[index]=i\n",
    "                output_centers[index]=center\n",
    "            index += 1\n",
    "        center += radius\n",
    "    unique_labels = np.unique(output_labels)\n",
    "    unique_labels_indexes=[]\n",
    "    output_average = np.zeros(shape=(len(input_set),))\n",
    "#     unique_labels_indexes=np.zeros(shape=(len(unique_labels),))\n",
    "    unique_labels_freqs=[]\n",
    "#     index=0\n",
    "    for i in unique_labels:\n",
    "        a=find_in_list(output_labels,i)\n",
    "        unique_labels_indexes.append(a)\n",
    "        unique_labels_freqs.append(len(a))\n",
    "#         unique_labels_indexes[index]= find_in_list(input_set,i)\n",
    "#         index+=1\n",
    "\n",
    "    for i in unique_labels_indexes :\n",
    "        temp_values=[]\n",
    "        for j in i :\n",
    "            temp_values.append(input_set[j])\n",
    "#         mean=statistics.mean(temp_values)   \n",
    "        mean = Average(temp_values)\n",
    "        for j in i:\n",
    "            output_average[j]=mean\n",
    "        mean=0\n",
    "            \n",
    "    len_output_labels = len(output_labels)\n",
    "    len_unique_output_labels = len(np.unique(output_labels))\n",
    "    percentage_main = len_unique_output_labels / len_output_labels\n",
    "    percentage_unused = len_unique_output_labels / steps\n",
    "\n",
    "    return  output_labels , output_centers, output_average , steps ,percentage_main ,percentage_unused ,len_unique_output_labels,len_output_labels,unique_labels_indexes,unique_labels_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases_labels,biases_centers,biases_average,steps,percentage_main,percentage_unused,len_unique_biases_labels,len_biases_labels,biases_unique_labels_indexes,biases_unique_labels_freqs= analyzer(biases,min_biases,max_biases,0.01)\n",
    "# print(biases_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncator(input_set,size):#.2f\n",
    "    out=[0] * len(input_set)\n",
    "    counter=0\n",
    "    for i in input_set:\n",
    "        s=float(format(i,size))\n",
    "        out[counter]=s\n",
    "        counter+=1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8280\n",
      "8278\n",
      "2658\n",
      "0.6789855072463769\n"
     ]
    }
   ],
   "source": [
    "a=truncator(biases,\".3f\")\n",
    "print(len(biases))\n",
    "print(len(np.unique(biases)))\n",
    "print(len(np.unique(a)))\n",
    "print(1-float(len(np.unique(a)))/float(len(biases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6990272\n",
      "6697665\n",
      "1362\n",
      "0.9998051577964349\n"
     ]
    }
   ],
   "source": [
    "v=truncator(weights,\".3f\")\n",
    "print(len(weights))\n",
    "print(len(np.unique(weights)))\n",
    "print(len(np.unique(v)))\n",
    "print(1-float(len(np.unique(v)))/float(len(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6990272\n",
      "6697665\n",
      "8236\n",
      "0.9988217911978247\n"
     ]
    }
   ],
   "source": [
    "b=truncator(weights,\".4f\")\n",
    "print(len(weights))\n",
    "print(len(np.unique(weights)))\n",
    "print(len(np.unique(b)))\n",
    "print(1-float(len(np.unique(b)))/float(len(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6990272\n",
      "6697665\n",
      "45996\n",
      "0.9934199985351071\n"
     ]
    }
   ],
   "source": [
    "c=truncator(weights,\".5f\")\n",
    "print(len(weights))\n",
    "print(len(np.unique(weights)))\n",
    "print(len(np.unique(c)))\n",
    "print(1-float(len(np.unique(c)))/float(len(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6990272\n",
      "6697665\n",
      "262424\n",
      "0.962458685441711\n"
     ]
    }
   ],
   "source": [
    "d=truncator(weights,\".6f\")\n",
    "print(len(weights))\n",
    "print(len(np.unique(weights)))\n",
    "print(len(np.unique(d)))\n",
    "print(1-float(len(np.unique(d)))/float(len(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6990272\n",
      "6697665\n",
      "1449949\n",
      "0.7925761687098871\n"
     ]
    }
   ],
   "source": [
    "e=truncator(weights,\".7f\")\n",
    "print(len(weights))\n",
    "print(len(np.unique(weights)))\n",
    "print(len(np.unique(e)))\n",
    "print(1-float(len(np.unique(e)))/float(len(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6990272\n",
      "6697665\n",
      "4985037\n",
      "0.28686079740530845\n"
     ]
    }
   ],
   "source": [
    "f=truncator(weights,\".8f\")\n",
    "print(len(weights))\n",
    "print(len(np.unique(weights)))\n",
    "print(len(np.unique(f)))\n",
    "print(1-float(len(np.unique(f)))/float(len(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6990272\n",
      "6697665\n",
      "6620079\n",
      "0.0529583112073464\n"
     ]
    }
   ],
   "source": [
    "g=truncator(weights,\".9f\")\n",
    "print(len(weights))\n",
    "print(len(np.unique(weights)))\n",
    "print(len(np.unique(g)))\n",
    "print(1-float(len(np.unique(g)))/float(len(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len_unique_biases_labels)\n",
    "print(len_biases_labels)\n",
    "print(percentage_main)\n",
    "print(percentage_unused)\n",
    "print(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('biases_labels.txt', 'w') as f:\n",
    "    for item in biases_labels:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "with open('biases_centers.txt', 'w') as f2:\n",
    "    for item in biases_centers:\n",
    "        f2.write(\"%s\\n\" % item) \n",
    "with open('biases.txt', 'w') as f3:\n",
    "    for item in biases:\n",
    "        f3.write(\"%s\\n\" % item) \n",
    "with open('biases_averages.txt', 'w') as f4:\n",
    "    for item in biases_average:\n",
    "        f4.write(\"%s\\n\" % item)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums=[i for i in range(len(biases_unique_labels_freqs))]\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Freq\")\n",
    "plt.title(\"Labels Freqs\")\n",
    "plt.plot(nums,biases_unique_labels_freqs,color=\"green\",linewidth=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_labels,weights_centers,weights_average,weights_steps,weights_percentage_main,weights_percentage_unused,len_unique_weights_labels,len_weights_labels,weights_unique_labels_indexes,weights_unique_labels_freqs= analyzer(weights,min_weights,max_weights,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len_unique_weights_labels)\n",
    "print(len_weights_labels)\n",
    "print(weights_percentage_main)\n",
    "print(weights_percentage_unused)\n",
    "print(weights_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('weights_labels.txt', 'w') as f:\n",
    "    for item in weights_labels:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "with open('weights_centers.txt', 'w') as f2:\n",
    "    for item in weights_centers:\n",
    "        f2.write(\"%s\\n\" % item) \n",
    "with open('weights.txt', 'w') as f3:\n",
    "    for item in weights:\n",
    "        f3.write(\"%s\\n\" % item) \n",
    "with open('weights_averages.txt', 'w') as f4:\n",
    "    for item in weights_average:\n",
    "        f4.write(\"%s\\n\" % item)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums=[i for i in range(len(weights_unique_labels_freqs))]\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Freq\")\n",
    "plt.title(\"Labels Freqs\")\n",
    "plt.plot(nums,weights_unique_labels_freqs,color=\"green\",linewidth=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
